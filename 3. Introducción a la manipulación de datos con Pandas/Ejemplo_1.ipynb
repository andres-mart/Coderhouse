{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libreria Pandas\n",
    "\n",
    "## Series\n",
    "*One-dimensional ndarray with axis labels (including time series).*\n",
    "\n",
    "Link a documentación:\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.Series.html\n",
    "\n",
    "\n",
    "Un objeto Series tiene dos componentes: un índice y un vector de datos, ambos con la misma longitud. El índice contiene valores únicos y, por lo general, ordenados, y se usa para acceder a valores individuales de los datos.\n",
    "\n",
    "\n",
    "## Dataframes\n",
    "\n",
    "*Two-dimensional, size-mutable, potentially heterogeneous tabular data.*\n",
    "\n",
    "Link a documentación:\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/frame.html\n",
    "\n",
    "Un dataframe esencialmente es una tabla con columnas y filas indexadas, de forma tal que podemos acceder fácilmente a filas mediante el índice. También podemos unir, separar o filtrar dataframes trabajando sobre el índice. En general, los dataframes le van a resultar bastante familiares a quienes sepan SQL.\n",
    "\n",
    "Los dataframes pueden tener datos no heterogéneos y además son **objetos** con **métodos** útiles para extraer información de forma rápida (por ejemplo, computar histogramas de valores). También es posible convertirlos a *arrays de Numpy* si así lo necesitamos, aunque no lo vamos a hacer a menos que sea realmente necesario."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creando Series"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A partir de listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         a\n",
      "1      bien\n",
      "2    [3, 8]\n",
      "3         c\n",
      "4         7\n",
      "5    (a, 3)\n",
      "6      10.8\n",
      "dtype: object\n",
      "<class 'pandas.core.series.Series'>\n",
      "uno            a\n",
      "dos         bien\n",
      "tres      [3, 8]\n",
      "cuatro         c\n",
      "cinco          7\n",
      "seis      (a, 3)\n",
      "siete       10.8\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "lista = ['a','bien',[3,8],'c',7,('a',3),10.8]\n",
    "s1 = pd.Series(lista)\n",
    "print(s1)\n",
    "print(type(s1))\n",
    "\n",
    "indices = ['uno', 'dos','tres','cuatro','cinco','seis', 'siete']\n",
    "s2 = pd.Series(index=indices, data=lista)\n",
    "print(s2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A partir de diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    10\n",
      "B    20\n",
      "C    30\n",
      "dtype: int64\n",
      "{'uno': 'a', 'dos': 'b', 'tres': 3, 'cuatro': 'c', 'cinco': 7, 'seis': 'd', 'siete': 10}\n",
      "uno        a\n",
      "dos        b\n",
      "tres       3\n",
      "cuatro     c\n",
      "cinco      7\n",
      "seis       d\n",
      "siete     10\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Creamos una serie a partir de un diccionario:\n",
    "d1 = {'A' : 10, 'B' : 20, 'C' : 30} # clave('{}') y valor \n",
    "series1 = pd.Series(d1)\n",
    "print(series1)\n",
    "\n",
    "\n",
    "# Creamos un diccionario a partir de dos listas\n",
    "valores = ['a','b',3,'c',7,'d',10]\n",
    "indices = ['uno', 'dos','tres','cuatro','cinco','seis', 'siete']\n",
    "d2 = dict(zip(indices, valores))\n",
    "print(d2)\n",
    "\n",
    "series2 = pd.Series(d2)\n",
    "print(series2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A partir de arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 8 7 6 5 4 3 2 1]\n",
      "0    81\n",
      "1    64\n",
      "2    49\n",
      "3    36\n",
      "4    25\n",
      "5    16\n",
      "6     9\n",
      "7     4\n",
      "8     1\n",
      "dtype: int32\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(9,0,-1) # Crear un rango de 9 a 1 contando uno a uno (hacia atras)\n",
    "print(x)\n",
    "s = pd.Series(data=x**2) # x**2 devuelve el valor de cada elemento de x elevado al cuadrado\n",
    "\n",
    "print(s)\n",
    "print(type(s))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operaciones con Series"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modificando una serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([0, 1, 2, 3, 4])\n",
    "s.replace(0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      10\n",
       "1     a.3\n",
       "2    casa\n",
       "3    auto\n",
       "4    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([10, 'a.3', 'casa', 'b', 'a'])\n",
    "s.replace({'a': None, 'b':'auto'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operando con series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2.0\n",
      "1    NaN\n",
      "2    5.0\n",
      "3   -1.0\n",
      "4    0.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    2.0\n",
       "1    NaN\n",
       "2    7.0\n",
       "3    6.0\n",
       "4    6.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suma acumulada:\n",
    "s = pd.Series([2, np.nan, 5, -1, 0])\n",
    "print(s)\n",
    "\n",
    "s.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halcon    390.0\n",
      "Halcon    350.0\n",
      "Loro       30.0\n",
      "Loro       20.0\n",
      "Name: Velocidad max, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Halcon    370.0\n",
       "Loro       25.0\n",
       "Name: Velocidad max, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agrupando datos:\n",
    "\n",
    "ser = pd.Series(data=[390., 350., 30., 20.], index=['Halcon', 'Halcon', 'Loro', 'Loro'], name=\"Velocidad max\")\n",
    "print(ser)\n",
    "ser.groupby(level=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California         NaN\n",
       "Ohio           70000.0\n",
       "Oregon         32000.0\n",
       "Texas         142000.0\n",
       "Utah               NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sumamos dos series:\n",
    "a = pd.Series([35000,71000,16000,5000],index=['Ohio','Texas','Oregon','Utah'])\n",
    "b = pd.Series([np.nan,71000,16000,35000],index=['California', 'Texas', 'Oregon', 'Ohio'])\n",
    "\n",
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California         NaN\n",
       "Ohio           70000.0\n",
       "Oregon         32000.0\n",
       "Texas         142000.0\n",
       "Utah            5000.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sumamos la serie con el función 'add()':\n",
    "ab = a.add(b, fill_value=0)\n",
    "\n",
    "ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>35000.0</td>\n",
       "      <td>35000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>71000.0</td>\n",
       "      <td>71000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>16000.0</td>\n",
       "      <td>16000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0        1\n",
       "Ohio        35000.0  35000.0\n",
       "Texas       71000.0  71000.0\n",
       "Oregon      16000.0  16000.0\n",
       "Utah         5000.0      NaN\n",
       "California      NaN      NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenamos las series anteriores:\n",
    "pd.concat((a,b), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creando Dataframes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A partir de un diccionario\n",
    "\n",
    "\n",
    "Una forma de construir `dataframes` es a partir de diccionarios, de forma tal que asignamos una **lista a cada llave**, que representa una columna del dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            alumno  primer parcial  segundo parcial observaciones       DNI\n",
      "0           Zutano               7               10       ninguna  23000000\n",
      "1          Mengano               8                9         libre  12389100\n",
      "2             Pepe               7                4       ninguna     99999\n",
      "3  Fulanito, Cosme               4               10         libre      1001\n",
      "4            Maria              10               10        oyente  30406011\n"
     ]
    }
   ],
   "source": [
    "# Tenemos un diccionario donde, para cada alumno tenemos 'nombre', 'nota primer parcial',\n",
    "# 'nota segundo parcial', 'observaciones' y 'DNI'\n",
    "datos = {'alumno': ['Zutano', 'Mengano', 'Pepe' ,'Fulanito, Cosme', 'Maria'], \n",
    "         'primer parcial': [7, 8,7,4, 10], 'segundo parcial': [10,9,4,10,10], \n",
    "         'observaciones':['ninguna','libre','ninguna','libre','oyente'], \n",
    "         'DNI':[23000000, 12389100, 99999, 1001,30406011]}\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(datos)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que las filas están identificadas con números (0,1,2,..). Esos números corresponden al índice (*index*). Podemos obtener las columnas y el índice de un dataframe como listas usando los siguientes métodos:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A partir de un archivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            alumno  primer parcial  segundo parcial observaciones       DNI\n",
      "0           Zutano               7               10       ninguna  23000000\n",
      "1          Mengano               8                9         libre  12389100\n",
      "2             Pepe               7                4       ninguna     99999\n",
      "3  Fulanito, Cosme               4               10         libre      1001\n",
      "4            Maria              10               10        oyente  30406011\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_table(\"C:\\\\Users\\\\andre\\\\OneDrive\\\\Escritorio\\\\ejemplo.txt\", delimiter=\";\")\n",
    "print(df)\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alumno', 'primer parcial', 'segundo parcial', 'observaciones', 'DNI']\n",
      "[0, 1, 2, 3, 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     7\n",
       "1     8\n",
       "2     7\n",
       "3     4\n",
       "4    10\n",
       "Name: primer parcial, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimimos las columnas con las que cuenta el Dataframe:\n",
    "print(list(df.columns))\n",
    "# Imprimimos el índice del Dataframe:\n",
    "print(list(df.index))\n",
    "\n",
    "# Imprimimos la columna 'primer parcial' del Dataframe:\n",
    "df['primer parcial']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series y dataframes, a partir de un dataframe\n",
    "\n",
    "Podemos ademas seleccionar una columna del dataframe como si se tratase de un diccionario. El objeto resultante se llama \"series\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             Zutano\n",
      "1            Mengano\n",
      "2               Pepe\n",
      "3    Fulanito, Cosme\n",
      "4              Maria\n",
      "Name: alumno, dtype: object\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# Imprimimos la columna de 'alumno':\n",
    "print(df['alumno'])\n",
    "\n",
    "# Seleccionamos la columna 'alumno': \n",
    "print(type(df['alumno']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener filas en vez de columnas, podemos usar el método df.loc con una lista de los índices que queremos acceder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alumno              Mengano\n",
      "primer parcial            8\n",
      "segundo parcial           9\n",
      "observaciones         libre\n",
      "DNI                12389100\n",
      "Name: 1, dtype: object\n",
      "<class 'pandas.core.series.Series'>\n",
      "    alumno  primer parcial  segundo parcial observaciones       DNI\n",
      "1  Mengano               8                9         libre  12389100\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Cual es la diferencia?\n",
    "\n",
    "# Como serie:\n",
    "print(df.loc[1])\n",
    "print(type(df.loc[1]))\n",
    "\n",
    "\n",
    "# Como dataframe:\n",
    "print(df.loc[[1]])\n",
    "print(type(df.loc[[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alumno</th>\n",
       "      <th>primer parcial</th>\n",
       "      <th>segundo parcial</th>\n",
       "      <th>observaciones</th>\n",
       "      <th>DNI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pepe</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>ninguna</td>\n",
       "      <td>99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fulanito, Cosme</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>libre</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maria</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>oyente</td>\n",
       "      <td>30406011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            alumno  primer parcial  segundo parcial observaciones       DNI\n",
       "2             Pepe               7                4       ninguna     99999\n",
       "3  Fulanito, Cosme               4               10         libre      1001\n",
       "4            Maria              10               10        oyente  30406011"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# O bien:\n",
    "df.loc[2:4]   # = df.loc[[2,3,4]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir un indice diferente\n",
    "\n",
    "Podríamos haber querido otro índice en vez de [0,1,2,...] para nuestro dataframe. En ese caso, le agregamos el parámetro index a la hora de crearlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                alumno  primer parcial  segundo parcial observaciones  \\\n",
      "uno             Zutano               7               10       ninguna   \n",
      "3              Mengano               8                9         libre   \n",
      "cinco             Pepe               7                4       ninguna   \n",
      "7      Fulanito, Cosme               4               10         libre   \n",
      "nueve            Maria              10               10        oyente   \n",
      "\n",
      "            DNI  \n",
      "uno    23000000  \n",
      "3      12389100  \n",
      "cinco     99999  \n",
      "7          1001  \n",
      "nueve  30406011  \n"
     ]
    }
   ],
   "source": [
    "datos = {'alumno': ['Zutano', 'Mengano', 'Pepe' ,'Fulanito, Cosme', 'Maria'], \n",
    "         'primer parcial': [7, 8,7,4, 10], 'segundo parcial': [10,9,4,10,10], \n",
    "         'observaciones':['ninguna','libre','ninguna','libre','oyente'], \n",
    "         'DNI':[23000000, 12389100, 99999, 1001,30406011]}\n",
    "df = pd.DataFrame(datos, index=['uno', 3,'cinco', 7,'nueve'])\n",
    "print(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y el proceso de ubicar filas es igual al anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alumno</th>\n",
       "      <th>primer parcial</th>\n",
       "      <th>segundo parcial</th>\n",
       "      <th>observaciones</th>\n",
       "      <th>DNI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fulanito, Cosme</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>libre</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uno</th>\n",
       "      <td>Zutano</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>ninguna</td>\n",
       "      <td>23000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              alumno  primer parcial  segundo parcial observaciones       DNI\n",
       "7    Fulanito, Cosme               4               10         libre      1001\n",
       "uno           Zutano               7               10       ninguna  23000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[[7,'uno']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modificar el índice \n",
    "\n",
    "Puede que ya hayamos creado un dataframe y después de hacerlo nos demos cuenta de que una de las columnas tiene más sentido como índice que otra. En ese caso, lo que buscamos es reindexar el dataframe usando los valores de esa columna. En general conviene utilizar como índice algo que sea un identificador único de cada elemento en el dataframe; en este caso, el DNI puede cumplir con esa función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   alumno  primer parcial  segundo parcial observaciones\n",
      "DNI                                                                     \n",
      "23000000           Zutano               7               10       ninguna\n",
      "12389100          Mengano               8                9         libre\n",
      "99999                Pepe               7                4       ninguna\n",
      "1001      Fulanito, Cosme               4               10         libre\n",
      "30406011            Maria              10               10        oyente\n"
     ]
    }
   ],
   "source": [
    "df_DNI = df.set_index('DNI')\n",
    "print(df_DNI)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos de limpieza de datos\n",
    "Una ventaja del dataframe son los métodos que tiene para la limpieza de datos. Esto es útil si por ejemplo queremos descartar filas o columnas duplicadas o con datos faltantes. Supongamos que tenemos un dataframe en el cual faltan algunos datos (identificados con \"nan\") y algunas de las filas están duplicadas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            alumno  primer parcial  segundo parcial observaciones       DNI\n",
      "0           Zutano             7.0             10.0       ninguna  23000000\n",
      "1          Mengano             8.0              9.0         libre  12389100\n",
      "2           Zutano             7.0             10.0       ninguna  23000000\n",
      "3             Pepe             7.0              4.0       ninguna     99999\n",
      "4  Fulanito, Cosme             NaN             10.0         libre      1001\n",
      "5            Maria            10.0              NaN        oyente  30406011\n"
     ]
    }
   ],
   "source": [
    "import numpy as np          # Necesitamos la libreria numpy para escribir 'nan'\n",
    "datos = {'alumno': ['Zutano', 'Mengano', 'Zutano','Pepe' ,'Fulanito, Cosme', 'Maria'], \n",
    "         'primer parcial': [7, 8,7,7,np.nan, 10], 'segundo parcial': [10,9,10,4,10,np.nan], \n",
    "         'observaciones':['ninguna','libre','ninguna','ninguna','libre','oyente'], \n",
    "         'DNI':[23000000, 12389100,23000000, 99999, 1001,30406011]}\n",
    "df = pd.DataFrame(datos)\n",
    "print(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos las columnas que tienen Nan. Para eso usamos el método df.dropna():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    alumno  primer parcial  segundo parcial observaciones       DNI\n",
      "0   Zutano             7.0             10.0       ninguna  23000000\n",
      "1  Mengano             8.0              9.0         libre  12389100\n",
      "2   Zutano             7.0             10.0       ninguna  23000000\n",
      "3     Pepe             7.0              4.0       ninguna     99999\n"
     ]
    }
   ],
   "source": [
    "df_2 = df.dropna()\n",
    "print(df_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observemos que había varias maneras de hacer esto. Por ejemplo, podríamos haber querido eliminar las columnas que tenían un 'nan', en vez de las filas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            alumno observaciones       DNI\n",
      "0           Zutano       ninguna  23000000\n",
      "1          Mengano         libre  12389100\n",
      "2           Zutano       ninguna  23000000\n",
      "3             Pepe       ninguna     99999\n",
      "4  Fulanito, Cosme         libre      1001\n",
      "5            Maria        oyente  30406011\n"
     ]
    }
   ],
   "source": [
    "df_3 = df.dropna(axis=1)\n",
    "print(df_3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O podríamos haber querido eliminar las filas que tengan TODOS los valores 'nan'. También podríamos haber específicado un subset de las columnas para verificar si las filas tienen valores 'nan' y removerlas en ese caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            alumno  primer parcial  segundo parcial observaciones       DNI\n",
      "0           Zutano             7.0             10.0       ninguna  23000000\n",
      "1          Mengano             8.0              9.0         libre  12389100\n",
      "2           Zutano             7.0             10.0       ninguna  23000000\n",
      "3             Pepe             7.0              4.0       ninguna     99999\n",
      "4  Fulanito, Cosme             NaN             10.0         libre      1001\n",
      "5            Maria            10.0              NaN        oyente  30406011\n"
     ]
    }
   ],
   "source": [
    "# El argumento how = 'all' especifica que se deben eliminar solo aquellas filas en las que \n",
    "# todos los valores son NaN. Esto significa que si una fila tiene algún valor no NaN, \n",
    "# esa fila no será eliminada.\n",
    "\n",
    "df_4 = df.dropna(how = 'all')\n",
    "print(df_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    alumno  primer parcial  segundo parcial observaciones       DNI\n",
      "0   Zutano             7.0             10.0       ninguna  23000000\n",
      "1  Mengano             8.0              9.0         libre  12389100\n",
      "2   Zutano             7.0             10.0       ninguna  23000000\n",
      "3     Pepe             7.0              4.0       ninguna     99999\n",
      "5    Maria            10.0              NaN        oyente  30406011\n"
     ]
    }
   ],
   "source": [
    "# El argumento subset = ['primer parcial', 'observaciones'] especifica que solo se deben \n",
    "# eliminar las filas en las que los valores en las columnas 'primer parcial' y 'observaciones' \n",
    "# sean NaN.\n",
    "\n",
    "df_5 = df.dropna(subset = ['primer parcial','observaciones'])\n",
    "print(df_5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, puede que no queramos crear un dataframe nuevo. En ese caso, hacemos lo siguiente y modificamos el dataframe original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    alumno  primer parcial  segundo parcial observaciones       DNI\n",
      "0   Zutano             7.0             10.0       ninguna  23000000\n",
      "1  Mengano             8.0              9.0         libre  12389100\n",
      "2   Zutano             7.0             10.0       ninguna  23000000\n",
      "3     Pepe             7.0              4.0       ninguna     99999\n"
     ]
    }
   ],
   "source": [
    "df.dropna(inplace = True)\n",
    "print(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede que no queramos eliminar las filas o columnas que tienen 'nan', sino llenar esas entradas usando algun valor fijo, o un promedio de las demás entradas de la fila o la columna. Para eso volvemos a definir el dataframe (porque lo modificamos en el bloque de código anterior) y luego probamos el método df.fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            alumno  primer parcial  segundo parcial observaciones       DNI\n",
      "0           Zutano             7.0             10.0       ninguna  23000000\n",
      "1          Mengano             8.0              9.0         libre  12389100\n",
      "2           Zutano             7.0             10.0       ninguna  23000000\n",
      "3             Pepe             7.0              4.0       ninguna     99999\n",
      "4  Fulanito, Cosme             NaN             10.0         libre      1001\n",
      "5            Maria            10.0              NaN        oyente  30406011\n",
      "            alumno  primer parcial  segundo parcial observaciones       DNI\n",
      "0           Zutano             7.0             10.0       ninguna  23000000\n",
      "1          Mengano             8.0              9.0         libre  12389100\n",
      "2           Zutano             7.0             10.0       ninguna  23000000\n",
      "3             Pepe             7.0              4.0       ninguna     99999\n",
      "4  Fulanito, Cosme             0.0             10.0         libre      1001\n",
      "5            Maria            10.0              0.0        oyente  30406011\n"
     ]
    }
   ],
   "source": [
    "datos = {'alumno': ['Zutano', 'Mengano', 'Zutano','Pepe' ,'Fulanito, Cosme', 'Maria'], \n",
    "         'primer parcial': [7, 8,7,7,np.nan, 10], \n",
    "         'segundo parcial': [10,9,10,4,10,np.nan], \n",
    "         'observaciones':['ninguna','libre','ninguna','ninguna','libre','oyente'], \n",
    "         'DNI':[23000000, 12389100,23000000, 99999, 1001,30406011]}\n",
    "df = pd.DataFrame(datos)\n",
    "print(df)\n",
    "df_2 = df.fillna(0)\n",
    "print(df_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto claramente reeplaza los valores faltantes usando un valor prefijado. Podemos también usar medias o medianas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            alumno  primer parcial  segundo parcial observaciones       DNI\n",
      "0           Zutano             7.0             10.0       ninguna  23000000\n",
      "1          Mengano             8.0              9.0         libre  12389100\n",
      "2           Zutano             7.0             10.0       ninguna  23000000\n",
      "3             Pepe             7.0              4.0       ninguna     99999\n",
      "4  Fulanito, Cosme             7.8             10.0         libre      1001\n",
      "5            Maria            10.0              7.8        oyente  30406011\n"
     ]
    }
   ],
   "source": [
    "a = df['primer parcial']\n",
    "df_3 = df.fillna(a.mean())\n",
    "print(df_3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, en 'a' están los valores de la columna 'primer parcial'. Luego, dentro de 'fillna' ponemos  'a.mean()' que computa el valor medio de todas las entradas que no son 'nan' de esa columna. Ese valor es 7.8, el cual se completa en todas las entradas que tienen 'nan'.\n",
    "\n",
    "Es lógico preguntarse si en realidad, nos gustaría reemplazar el 'nan' de la columna 'segundo parcial' por un promedio de los valores de esa columna, y no de 'primer parcial'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            alumno  primer parcial  segundo parcial observaciones       DNI\n",
      "0           Zutano             7.0             10.0       ninguna  23000000\n",
      "1          Mengano             8.0              9.0         libre  12389100\n",
      "2           Zutano             7.0             10.0       ninguna  23000000\n",
      "3             Pepe             7.0              4.0       ninguna     99999\n",
      "4  Fulanito, Cosme             7.8             10.0         libre      1001\n",
      "5            Maria            10.0              8.6        oyente  30406011\n"
     ]
    }
   ],
   "source": [
    "a = df['primer parcial']\n",
    "b = df['segundo parcial']\n",
    "fill_dict = {'primer parcial':a.mean(), 'segundo parcial':b.mean()}\n",
    "df_4 = df.fillna(fill_dict)\n",
    "print(df_4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que ahora usa valores diferentes para completar los 'nan' de cada columna (7.8 y 8.6). La forma de hacerlo es pasar un diccionario donde las llaves indican las columnas y los valores, por lo que debe ser reemplazado el nan.\n",
    "\n",
    "Obviamente el valor medio únicamente tiene sentido para datos numéricos, pero podemos reemplazar los datos de otras formas si los datos son no numéricos (por ejemplo, por la entrada más frecuente).\n",
    "\n",
    "Puede que querramos filtrar los datos mediante algún criterio distinto, por ejemplo, retener únicamente a los alumnos libres, o bien a aquellos cuyo primer parcial fue mayor a 7.\n",
    "\n",
    "Una forma sencilla es iterar el índice, y eliminar las filas que no cumplan con la condición dada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            alumno  primer parcial  segundo parcial observaciones       DNI\n",
      "1          Mengano             8.0              9.0         libre  12389100\n",
      "4  Fulanito, Cosme             NaN             10.0         libre      1001\n"
     ]
    }
   ],
   "source": [
    "datos = {'alumno': ['Zutano', 'Mengano', 'Zutano','Pepe' ,'Fulanito, Cosme', 'Maria'], \n",
    "         'primer parcial': [7, 8,7,7,np.nan, 10], \n",
    "         'segundo parcial': [10,9,10,4,10,np.nan], \n",
    "         'observaciones':['ninguna','libre','ninguna','ninguna','libre','oyente'], \n",
    "         'DNI':[23000000, 12389100,23000000, 99999, 1001,30406011]\n",
    "         }\n",
    "df = pd.DataFrame(datos)\n",
    "\n",
    "for x in df.index:\n",
    "  if not df.loc[x, \"observaciones\"] == 'libre':\n",
    "    df.drop(x, inplace = True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            alumno  primer parcial  segundo parcial observaciones       DNI\n",
      "1          Mengano             8.0              9.0         libre  12389100\n",
      "4  Fulanito, Cosme             NaN             10.0         libre      1001\n"
     ]
    }
   ],
   "source": [
    "# Una mejor forma de hacerlo:\n",
    "datos = {'alumno': ['Zutano', 'Mengano', 'Zutano','Pepe' ,'Fulanito, Cosme', 'Maria'], \n",
    "         'primer parcial': [7, 8,7,7,np.nan, 10], \n",
    "         'segundo parcial': [10,9,10,4,10,np.nan], \n",
    "         'observaciones':['ninguna','libre','ninguna','ninguna','libre','oyente'], \n",
    "         'DNI':[23000000, 12389100,23000000, 99999, 1001,30406011]\n",
    "         }\n",
    "df = pd.DataFrame(datos)\n",
    "\n",
    "df_libre = df[df['observaciones']=='libre']\n",
    "print(df_libre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            alumno  primer parcial  segundo parcial observaciones       DNI\n",
      "1          Mengano             8.0              9.0         libre  12389100\n",
      "4  Fulanito, Cosme             NaN             10.0         libre      1001\n",
      "5            Maria            10.0              NaN        oyente  30406011\n"
     ]
    }
   ],
   "source": [
    "# Utilizamos un 'loop for' para filtrar aquellos valores de la columna 'primer parcial' menores a 7:\n",
    "datos = {'alumno': ['Zutano', 'Mengano', 'Zutano','Pepe' ,'Fulanito, Cosme', 'Maria'], \n",
    "         'primer parcial': [7, 8,7,7,np.nan, 10], \n",
    "         'segundo parcial': [10,9,10,4,10,np.nan], \n",
    "         'observaciones':['ninguna','libre','ninguna','ninguna','libre','oyente'], \n",
    "         'DNI':[23000000, 12389100,23000000, 99999, 1001,30406011]\n",
    "         }\n",
    "df = pd.DataFrame(datos)\n",
    "\n",
    "# En este caso se muestran aquellos que fueron eliminados, es decir, mayores a 7:\n",
    "for x in df.index:\n",
    "  if df.loc[x, \"primer parcial\"] <= 7:\n",
    "    df.drop(x, inplace = True)\n",
    "print(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratando datos duplicados\n",
    "\n",
    "Por último, puede que querramos remover duplicados. La forma más sencilla de hacerlo es con el método 'drop_duplicates()':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            alumno  primer parcial  segundo parcial observaciones       DNI\n",
      "0           Zutano             7.0             10.0       ninguna  23000000\n",
      "1          Mengano             8.0              9.0         libre  12389100\n",
      "2           Zutano             7.0             10.0       ninguna  23000000\n",
      "3             Pepe             7.0              4.0       ninguna     99999\n",
      "4  Fulanito, Cosme             NaN             10.0         libre      1001\n",
      "5            Maria            10.0              NaN        oyente  30406011\n"
     ]
    }
   ],
   "source": [
    "datos = {'alumno': ['Zutano', 'Mengano', 'Zutano','Pepe' ,'Fulanito, Cosme', 'Maria'], \n",
    "         'primer parcial': [7, 8,7,7,np.nan, 10], \n",
    "         'segundo parcial': [10,9,10,4,10,np.nan], \n",
    "         'observaciones':['ninguna','libre','ninguna','ninguna','libre','oyente'], \n",
    "         'DNI':[23000000, 12389100,23000000, 99999, 1001,30406011]\n",
    "         }\n",
    "df = pd.DataFrame(datos)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            alumno  primer parcial  segundo parcial observaciones       DNI\n",
      "0           Zutano             7.0             10.0       ninguna  23000000\n",
      "1          Mengano             8.0              9.0         libre  12389100\n",
      "3             Pepe             7.0              4.0       ninguna     99999\n",
      "4  Fulanito, Cosme             NaN             10.0         libre      1001\n",
      "5            Maria            10.0              NaN        oyente  30406011\n"
     ]
    }
   ],
   "source": [
    "df_2 = df.drop_duplicates()\n",
    "print(df_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunos de los métodos que podemos aplicar a los dataframes son útiles para tener una idea de los valores de una columna sin tener que hacer demasiado trabajo. Esto es lo que podemos hacer con 'value_counts()', que nos devuelve todos los valores que toman las entradas de la columna y, la cantidad de veces que ocurren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ninguna    3\n",
       "libre      2\n",
       "oyente     1\n",
       "Name: observaciones, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['observaciones'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinar Dataframes\n",
    "\n",
    "Lo último que vamos a ver en este Notebook es cómo combinar dos o más dataframes en uno solo.\n",
    "\n",
    "La forma más sencilla es hacer append de un dataframe a otro, ambos con las mismas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            alumno  primer parcial  segundo parcial observaciones       DNI\n",
      "0           Zutano             7.0             10.0       ninguna  23000000\n",
      "1          Mengano             8.0              9.0         libre  12389100\n",
      "2           Zutano             7.0             10.0       ninguna  23000000\n",
      "3             Pepe             7.0              4.0       ninguna     99999\n",
      "4  Fulanito, Cosme             NaN             10.0         libre      1001\n",
      "5            Maria            10.0              NaN        oyente  30406011\n",
      "0            Diego            10.0              8.0       ninguna     23299\n",
      "1             Flor            10.0              8.0         libre   1043101\n",
      "2             José             8.0              8.0         libre   4406533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_4440\\2811770482.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_3 = df_1.append(df_2)\n"
     ]
    }
   ],
   "source": [
    "datos_1 = {'alumno': ['Zutano', 'Mengano', 'Zutano','Pepe' ,'Fulanito, Cosme', 'Maria'], \n",
    "           'primer parcial': [7, 8,7,7,np.nan, 10], \n",
    "           'segundo parcial': [10,9,10,4,10,np.nan], \n",
    "           'observaciones':['ninguna','libre','ninguna','ninguna','libre','oyente'], \n",
    "           'DNI':[23000000, 12389100,23000000, 99999, 1001,30406011]\n",
    "           }\n",
    "df_1 = pd.DataFrame(datos_1)\n",
    "\n",
    "datos_2 = {'alumno': ['Diego', 'Flor', 'José'], \n",
    "           'primer parcial': [10,10,8], \n",
    "           'segundo parcial': [8,8,8], \n",
    "           'observaciones':['ninguna','libre','libre'], \n",
    "           'DNI':[23299, 1043101,4406533]\n",
    "           }\n",
    "df_2 = pd.DataFrame(datos_2)\n",
    "\n",
    "df_3 = df_1.append(df_2)\n",
    "print(df_3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que esto tiene un potencial problema: aparecen filas que tienen el mismo valor del índice, lo cual puede complicar localizarlas.\n",
    "\n",
    "Para resolver este problema, podemos usar 'pd.concat' de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            alumno  primer parcial  segundo parcial observaciones       DNI\n",
      "0           Zutano             7.0             10.0       ninguna  23000000\n",
      "1          Mengano             8.0              9.0         libre  12389100\n",
      "2           Zutano             7.0             10.0       ninguna  23000000\n",
      "3             Pepe             7.0              4.0       ninguna     99999\n",
      "4  Fulanito, Cosme             NaN             10.0         libre      1001\n",
      "5            Maria            10.0              NaN        oyente  30406011\n",
      "6            Diego            10.0              8.0       ninguna     23299\n",
      "7             Flor            10.0              8.0         libre   1043101\n",
      "8             José             8.0              8.0         libre   4406533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_4440\\2166547122.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_3 = df_1.append(df_2, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df_3 = df_1.append(df_2, ignore_index = True)               \n",
    "print(df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            alumno  primer parcial  segundo parcial observaciones       DNI\n",
      "0           Zutano             7.0             10.0       ninguna  23000000\n",
      "1          Mengano             8.0              9.0         libre  12389100\n",
      "2           Zutano             7.0             10.0       ninguna  23000000\n",
      "3             Pepe             7.0              4.0       ninguna     99999\n",
      "4  Fulanito, Cosme             NaN             10.0         libre      1001\n",
      "5            Maria            10.0              NaN        oyente  30406011\n",
      "6            Diego            10.0              8.0       ninguna     23299\n",
      "7             Flor            10.0              8.0         libre   1043101\n",
      "8             José             8.0              8.0         libre   4406533\n"
     ]
    }
   ],
   "source": [
    "# O bien, podemos utilizar:\n",
    "df_3 = pd.concat( (df_1, df_2), axis = 0, join = \"outer\", ignore_index = True)\n",
    "print(df_3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*El argumento axis = 0 especifica que se debe concatenar los dataframes a lo largo del eje 0, es decir, que se deben unir las filas de los dataframes df_1 y df_2 para crear el dataframe df_3.*\n",
    "\n",
    "*El argumento join = \"outer\" especifica que el tipo de unión a realizar es una unión externa. Esto significa que se mantendrán todas las filas y columnas de ambos dataframes, y donde no haya correspondencia de valores, se completarán con NaN en el dataframe resultante df_3.*\n",
    "\n",
    "*El argumento ignore_index = True especifica que se debe ignorar el índice original de los dataframes df_1 y df_2 y crear un nuevo índice para el dataframe resultante df_3.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos cómo en este caso el índice se reinicia empezando desde 0. Por supuesto, como vimos antes, siempre podemos reindexar usando otra columna que sirva a ese propósito (el DNI sería la mejor opción).\n",
    "\n",
    "El proceso de unir o mergear dos dataframes con distintas columnas es familiar para aquellos con alguna experiencia en SQL. Supongamos que tenemos este dataframe reindexado por el DNI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   alumno  primer parcial  segundo parcial observaciones\n",
      "DNI                                                                     \n",
      "23000000           Zutano             7.0             10.0       ninguna\n",
      "12389100          Mengano             8.0              9.0         libre\n",
      "23000000           Zutano             7.0             10.0       ninguna\n",
      "99999                Pepe             7.0              4.0       ninguna\n",
      "1001      Fulanito, Cosme             NaN             10.0         libre\n",
      "30406011            Maria            10.0              NaN        oyente\n",
      "23299               Diego            10.0              8.0       ninguna\n",
      "1043101              Flor            10.0              8.0         libre\n",
      "4406533              José             8.0              8.0         libre\n"
     ]
    }
   ],
   "source": [
    "df_DNI = df_3.set_index('DNI')\n",
    "print(df_DNI)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que tenemos además otro dataframe indexado por el el DNI, con algún solapamiento parcial con este dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   alumno cuota al día  año que cursa\n",
      "3934444           Roberto           sí              2\n",
      "12389100          Mengano           sí              2\n",
      "2939393            Carlos           no              2\n",
      "10102394          Marisol           no              1\n",
      "1001      Fulanito, Cosme           sí              4\n"
     ]
    }
   ],
   "source": [
    "datos_1 = {'alumno': ['Roberto', 'Mengano', 'Carlos','Marisol' ,'Fulanito, Cosme'], \n",
    "           'cuota al día': ['sí','sí','no','no','sí'], \n",
    "           'año que cursa': [2, 2, 2, 1, 4]\n",
    "           }\n",
    "df_1 = pd.DataFrame(datos_1, index=[3934444, 12389100, 2939393, 10102394,1001])\n",
    "print(df_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos combinar toda esta información en una misma tabla, de forma tal que, el índice determine cómo se unen las filas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            alumno  primer parcial  segundo parcial observaciones  \\\n",
      "0          Mengano             8.0              9.0         libre   \n",
      "1  Fulanito, Cosme             NaN             10.0         libre   \n",
      "\n",
      "  cuota al día  año que cursa  \n",
      "0           sí              2  \n",
      "1           sí              4  \n"
     ]
    }
   ],
   "source": [
    "df_all = pd.merge(df_DNI, df_1, how = \"inner\")\n",
    "print(df_all)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*El argumento how = \"inner\" especifica que se debe realizar una operación de unión interna. Esto significa que solo se conservarán las filas que tienen correspondencia en ambos dataframes. En otras palabras, solo se incluirán las filas en las que los valores de una columna clave común existan tanto en df_DNI como en df_1.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el merge unión a los que estaban en la intersección de ambos dataframes. Esto cambia a la únion si modificamos 'inner' por 'outer':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             alumno  primer parcial  segundo parcial observaciones  \\\n",
      "0            Zutano             7.0             10.0       ninguna   \n",
      "1            Zutano             7.0             10.0       ninguna   \n",
      "2           Mengano             8.0              9.0         libre   \n",
      "3              Pepe             7.0              4.0       ninguna   \n",
      "4   Fulanito, Cosme             NaN             10.0         libre   \n",
      "5             Maria            10.0              NaN        oyente   \n",
      "6             Diego            10.0              8.0       ninguna   \n",
      "7              Flor            10.0              8.0         libre   \n",
      "8              José             8.0              8.0         libre   \n",
      "9           Roberto             NaN              NaN           NaN   \n",
      "10           Carlos             NaN              NaN           NaN   \n",
      "11          Marisol             NaN              NaN           NaN   \n",
      "\n",
      "   cuota al día  año que cursa  \n",
      "0           NaN            NaN  \n",
      "1           NaN            NaN  \n",
      "2            sí            2.0  \n",
      "3           NaN            NaN  \n",
      "4            sí            4.0  \n",
      "5           NaN            NaN  \n",
      "6           NaN            NaN  \n",
      "7           NaN            NaN  \n",
      "8           NaN            NaN  \n",
      "9            sí            2.0  \n",
      "10           no            2.0  \n",
      "11           no            1.0  \n"
     ]
    }
   ],
   "source": [
    "df_all = pd.merge(df_DNI,df_1, how=\"outer\")\n",
    "print(df_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
